#summary One-sentence summary of this page.

= Introduction =

Add your content here.


= Details =

Add your content here.  Format your content with:
  * Text in *bold* or _italic_
  * Headings, paragraphs, and lists
  * Automatic links to other wiki pages
2nd Prepare a Wikimedia dump, with its offline on your DS
    want to have. You need this step only once for each dump
    , but of course again if you own a current version
    want to install.

    a) Invite a compressed XML dump of http://dumps.wikimedia.org/
       down. For the German Wikipedia, for example,

       http://dumps.wikimedia.org/dewiki/latest/dewiki-latest-pages-articles.xml.bz2

       The pages-*- articles.xml-bz2 "version is the version that
       You need, the others do not include the right or too many
       Info!

       The compressed file should be around 1.2 GB.

    b) Now comes the first tricky part:

       The file must be re-indexed, but we need a tool
       by http://code.google.com/p/wiki2touch/ Laden. Windows and MacOSX -
       Users take the appropriate "Wiki2TouchUtils_ *. zip" file
       "Featured downloads," Linux users check the source code by

       svn checkout http://wiki2touch.googlecode.com/svn/trunk/ wiki2touch-read-only

       , and compile the indexer with "make" in "linux / indexer"
       Directory.

       IMPORTANT: A picture index must not be created (on Linux-I),
       A second index of normalized umlauts should draw
(D-under Linux).

       Now you should about a 1 GB big "articles.bin".

    c) And there is thicker:

       The "articles.bin" must be in data and index will be split up. The
       The reason is that in some time to search more bearable,
       because the search index in the large file is SLOWLY! It must
       find out how big the front part of the file is the
       compressed data. This figure is at the byte Places 7-14
       in the "articles.bin". The steps in the Rough:

       Linux:
       ------

       The number of bytes may be measured by

       cat articles.bin | head-c 14 | tail-c 8 | od-A n-t d8

       Then you can enter through

           b $ split-BYTES articles.bin

       the file to the right place split (set for the $ BYTES
       figure). Renames the files:

       MV xaa dewiki.dat
MV xab dewiki.idx

       Windows:
       --------

       If the "articles.bin" with a hex editor (the Total Commander
       [http://www.ghisler.com] brings e.g. one with), looking for the bodies
       7-14, are probably only about the first three places not "00".
       Calculate the required number of bytes with the formula

       (1 point) * 1 + (2 * 256) + (3rd place) * 256 * 256 + ...

       e.g. starts with the file

       Hex: 64 65 1D 00 00 00 0E 3A 00 00 00 00 00 00 AD 0D
       Station: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
                                     |_______________________|

       then calculates

       0E = 14
       3A = 58

       BYTES = 14 + 58 * 256 = 14862

       Is the file behind this byte-count (also the total
       Commander).

       The large file (with the above-identified byte size) is to
       called her "dewiki.dat", the second, smaller, "dewiki.idx".

